{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:36:55.435123Z",
     "iopub.status.busy": "2025-06-04T15:36:55.434882Z",
     "iopub.status.idle": "2025-06-04T15:37:00.756292Z",
     "shell.execute_reply": "2025-06-04T15:37:00.755531Z",
     "shell.execute_reply.started": "2025-06-04T15:36:55.435104Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "import io \n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "YC_ACCESS_KEY_ID = os.getenv(\"YC_ACCESS_KEY_ID\")\n",
    "YC_SECRET_ACCESS_KEY = os.getenv(\"YC_SECRET_ACCESS_KEY\")\n",
    "YC_ENDPOINT_URL = os.getenv(\"YC_ENDPOINT_URL\")\n",
    "YC_BUCKET_NAME = os.getenv(\"YC_BUCKET_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session()\n",
    "s3_client = session.client(\n",
    "    service_name='s3',\n",
    "    endpoint_url=YC_ENDPOINT_URL,\n",
    "    aws_access_key_id=YC_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=YC_SECRET_ACCESS_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "file_names = [\"item_categories.csv.gzip\", \"items.csv.gzip\", \"sample_submission.csv.gzip\", \"shops.csv.gzip\", \"test.csv.gzip\", \"train.csv.gzip\"]\n",
    "data_location = \"filtered_data/\"\n",
    "\n",
    "data_storage = dict()\n",
    "for file_name in file_names:\n",
    "    response = s3_client.get_object(Bucket=YC_BUCKET_NAME, Key=f'{data_location}{file_name}')\n",
    "    data_storage[file_name[: len(file_name) - 9]] = pd.read_csv(io.BytesIO(response['Body'].read()), compression='gzip')\n",
    "\n",
    "data_storage[\"train\"]['date'] = pd.to_datetime(data_storage[\"train\"]['date'], format = '%Y-%m-%d')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preporation tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from src.data_preprocessor import DataPreprocessor\n",
    "\n",
    "proc = DataPreprocessor(data_storage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:37:00.757981Z",
     "iopub.status.busy": "2025-06-04T15:37:00.75741Z",
     "iopub.status.idle": "2025-06-04T15:37:03.271628Z",
     "shell.execute_reply": "2025-06-04T15:37:03.270846Z",
     "shell.execute_reply.started": "2025-06-04T15:37:00.75796Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sales           = data_storage['train']\n",
    "items           = data_storage['items']\n",
    "item_categories = data_storage['item_categories']\n",
    "shops           = data_storage['shops']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:37:04.01321Z",
     "iopub.status.busy": "2025-06-04T15:37:04.012635Z",
     "iopub.status.idle": "2025-06-04T15:37:04.021683Z",
     "shell.execute_reply": "2025-06-04T15:37:04.021004Z",
     "shell.execute_reply.started": "2025-06-04T15:37:04.013189Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_testlike_train(df):\n",
    "    matrix = []\n",
    "    min_date = df['date'].min()\n",
    "    for i in range(df['date_block_num'].min(), df['date_block_num'].max()+1):\n",
    "        shops = df[df['date_block_num'] == i]['shop_id'].unique()\n",
    "        items = df[df['date_block_num'] == i]['item_id'].unique()\n",
    "        month_start = min_date + pd.tseries.offsets.DateOffset(months = i)\n",
    "        matrix.append( np.array( list(product([i],[month_start],shops,items))))\n",
    "        \n",
    "    df_new = pd.DataFrame(np.vstack(matrix),columns = ['date_block_num','month_start','shop_id','item_id'])\n",
    "    pivot = pd.pivot_table(df, \n",
    "                            values = ['item_cnt_day'], \n",
    "                            index = ['date_block_num','shop_id','item_id'], \n",
    "                            aggfunc = 'sum').reset_index()\n",
    "    pivot2 = pd.pivot_table(df[df['item_cnt_day']>0], \n",
    "                            values = ['item_cnt_day'], \n",
    "                            index = ['date_block_num','shop_id','item_id'], \n",
    "                            aggfunc = 'count').reset_index()\n",
    "    pivot2.rename(columns={'item_cnt_day': 'purch_cnt_month'}, inplace=True)\n",
    "    \n",
    "    df_new = df_new.merge(right = pivot, how = 'left', on = ['date_block_num','shop_id','item_id'], sort = False)\n",
    "    df_new = df_new.merge(right = pivot2, how = 'left', on = ['date_block_num','shop_id','item_id'], sort = False)\n",
    "    \n",
    "    df_new.rename(columns={'item_cnt_day': 'item_cnt_month'}, inplace=True)\n",
    "    df_new['item_cnt_month'] = df_new['item_cnt_month'].clip(0,20)\n",
    "    df_new['item_cnt_month'].fillna(0, inplace=True)\n",
    "\n",
    "    df_new['date_block_num'] = df_new['date_block_num'].astype('int8')\n",
    "    df_new['shop_id'] = df_new['shop_id'].astype('int8')\n",
    "    df_new['item_id'] = df_new['item_id'].astype('int16')\n",
    "    df_new['item_cnt_month'] = df_new['item_cnt_month'].astype('float32')\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:37:04.022768Z",
     "iopub.status.busy": "2025-06-04T15:37:04.022514Z",
     "iopub.status.idle": "2025-06-04T15:37:57.375991Z",
     "shell.execute_reply": "2025-06-04T15:37:57.375379Z",
     "shell.execute_reply.started": "2025-06-04T15:37:04.022749Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_107464/3262818551.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_new['item_cnt_month'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.5 s, sys: 2.02 s, total: 18.5 s\n",
      "Wall time: 18.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = create_testlike_train(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = proc.add_month_and_days(df)\n",
    "\n",
    "df = proc.add_cat_features(df)\n",
    "\n",
    "cat_features = ['shop_city', 'shop_type', 'item_category_type', 'item_category_subtype']\n",
    "df = proc.encode_categorical_features(df, cat_features=cat_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:49:08.578336Z",
     "iopub.status.busy": "2025-06-04T15:49:08.578131Z",
     "iopub.status.idle": "2025-06-04T15:49:08.582851Z",
     "shell.execute_reply": "2025-06-04T15:49:08.582086Z",
     "shell.execute_reply.started": "2025-06-04T15:49:08.578321Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "columns_to_exclude = [\n",
    "                      'item_cnt_month',\n",
    "                      'purch_cnt_month',\n",
    "                      'month_start',\n",
    "                      'shop_name',\n",
    "                      'item_category_name',\n",
    "                      'item_name'\n",
    "                     ]\n",
    "cat_features = ['month',\n",
    "                'shop_id',\n",
    "                'shop_city',\n",
    "                'shop_type',\n",
    "                'item_category_id',\n",
    "                'item_category_type',\n",
    "                'item_category_subtype',\n",
    "                'days_in_month'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:49:08.583863Z",
     "iopub.status.busy": "2025-06-04T15:49:08.583627Z",
     "iopub.status.idle": "2025-06-04T15:52:16.069218Z",
     "shell.execute_reply": "2025-06-04T15:52:16.068658Z",
     "shell.execute_reply.started": "2025-06-04T15:49:08.583849Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# modeling\n",
    "params = {'metric': 'rmse',\n",
    "          'objective': 'mse',\n",
    "          'num_leaves': 255,\n",
    "          'learning_rate': 0.005,\n",
    "          'feature_fraction': 0.75,\n",
    "          'bagging_fraction': 0.75,\n",
    "          'bagging_freq': 5,\n",
    "          'force_col_wise' : True,\n",
    "          'random_state': 10}\n",
    "\n",
    "# Prepare training and validation datasets with categorical features\n",
    "train_data = lgb.Dataset(\n",
    "    df[(df['date_block_num'] >= 19) & (df['date_block_num'] < 33)].drop(columns_to_exclude, axis=1),\n",
    "    label=df[(df['date_block_num'] >= 19) & (df['date_block_num'] < 33)]['item_cnt_month'],\n",
    "    categorical_feature=cat_features\n",
    ")\n",
    "\n",
    "valid_data = lgb.Dataset(\n",
    "    df[df['date_block_num'] == 33].drop(columns_to_exclude, axis=1),\n",
    "    label=df[df['date_block_num'] == 33]['item_cnt_month'],\n",
    "    categorical_feature=cat_features,\n",
    "    reference=train_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.validation_schema import TimeSeriesRollingValidator\n",
    "\n",
    "validator = TimeSeriesRollingValidator(df, 'date_block_num', train_window=8, test_window=1)\n",
    "splits = validator.split_data_rolling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 518\n",
      "[LightGBM] [Info] Number of data points in the train set: 3191064, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.295206\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 1.05694\tvalid_1's rmse: 0.921393\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m lgb_model = \u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter_venv/lib/python3.12/site-packages/lightgbm/engine.py:322\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[32m    311\u001b[39m     cb(\n\u001b[32m    312\u001b[39m         callback.CallbackEnv(\n\u001b[32m    313\u001b[39m             model=booster,\n\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m         )\n\u001b[32m    320\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[43mbooster\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] = []\n\u001b[32m    325\u001b[39m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter_venv/lib/python3.12/site-packages/lightgbm/basic.py:4155\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, train_set, fobj)\u001b[39m\n\u001b[32m   4152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__set_objective_to_none:\n\u001b[32m   4153\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[33m\"\u001b[39m\u001b[33mCannot update due to null objective function.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4154\u001b[39m _safe_call(\n\u001b[32m-> \u001b[39m\u001b[32m4155\u001b[39m     \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4156\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4158\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4159\u001b[39m )\n\u001b[32m   4160\u001b[39m \u001b[38;5;28mself\u001b[39m.__is_predicted_cur_iter = [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.__num_dataset)]\n\u001b[32m   4161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished.value == \u001b[32m1\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "lgb_model = lgb.train(\n",
    "    params=params,\n",
    "    train_set=train_data,\n",
    "    num_boost_round=1500,\n",
    "    valid_sets=[train_data, valid_data],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=100), lgb.log_evaluation(100)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 868304,
     "sourceId": 8587,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python (Jupyter)",
   "language": "python",
   "name": "jupyter_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
