{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:36:55.435123Z",
     "iopub.status.busy": "2025-06-04T15:36:55.434882Z",
     "iopub.status.idle": "2025-06-04T15:37:00.756292Z",
     "shell.execute_reply": "2025-06-04T15:37:00.755531Z",
     "shell.execute_reply.started": "2025-06-04T15:36:55.435104Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "import io \n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "YC_ACCESS_KEY_ID = os.getenv(\"YC_ACCESS_KEY_ID\")\n",
    "YC_SECRET_ACCESS_KEY = os.getenv(\"YC_SECRET_ACCESS_KEY\")\n",
    "YC_ENDPOINT_URL = os.getenv(\"YC_ENDPOINT_URL\")\n",
    "YC_BUCKET_NAME = os.getenv(\"YC_BUCKET_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session()\n",
    "s3_client = session.client(\n",
    "    service_name='s3',\n",
    "    endpoint_url=YC_ENDPOINT_URL,\n",
    "    aws_access_key_id=YC_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=YC_SECRET_ACCESS_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "file_names = [\"item_categories.csv.gzip\", \"items.csv.gzip\", \"sample_submission.csv.gzip\", \"shops.csv.gzip\", \"test.csv.gzip\", \"sales_train.csv.gzip\"]\n",
    "data_location = \"compressed_data/\"\n",
    "\n",
    "data_storage = dict()\n",
    "for file_name in file_names:\n",
    "    response = s3_client.get_object(Bucket=YC_BUCKET_NAME, Key=f'{data_location}{file_name}')\n",
    "    data_storage[file_name[: len(file_name) - 9]] = pd.read_csv(io.BytesIO(response['Body'].read()), compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:37:00.757981Z",
     "iopub.status.busy": "2025-06-04T15:37:00.75741Z",
     "iopub.status.idle": "2025-06-04T15:37:03.271628Z",
     "shell.execute_reply": "2025-06-04T15:37:03.270846Z",
     "shell.execute_reply.started": "2025-06-04T15:37:00.75796Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import the data\n",
    "DATA_FOLDER = '/kaggle/input/competitive-data-science-predict-future-sales'\n",
    "\n",
    "sales           = data_storage['sales_train']\n",
    "items           = data_storage['items']\n",
    "item_categories = data_storage['item_categories']\n",
    "shops           = data_storage['shops']\n",
    "test            = data_storage['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:37:03.272761Z",
     "iopub.status.busy": "2025-06-04T15:37:03.272493Z",
     "iopub.status.idle": "2025-06-04T15:37:03.601413Z",
     "shell.execute_reply": "2025-06-04T15:37:03.600546Z",
     "shell.execute_reply.started": "2025-06-04T15:37:03.272737Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sales['date'] = pd.to_datetime(sales['date'], format = '%d.%m.%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:37:03.603351Z",
     "iopub.status.busy": "2025-06-04T15:37:03.603116Z",
     "iopub.status.idle": "2025-06-04T15:37:03.701407Z",
     "shell.execute_reply": "2025-06-04T15:37:03.700656Z",
     "shell.execute_reply.started": "2025-06-04T15:37:03.603333Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# exclude shops not in test\n",
    "sales = sales[sales['shop_id'].isin(test['shop_id'].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:37:03.996873Z",
     "iopub.status.busy": "2025-06-04T15:37:03.996618Z",
     "iopub.status.idle": "2025-06-04T15:37:04.011661Z",
     "shell.execute_reply": "2025-06-04T15:37:04.010789Z",
     "shell.execute_reply.started": "2025-06-04T15:37:03.996849Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_258218/2322608808.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sales['revenue'] = sales['item_price']*sales['item_cnt_day']\n"
     ]
    }
   ],
   "source": [
    "sales['revenue'] = sales['item_price']*sales['item_cnt_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:37:04.01321Z",
     "iopub.status.busy": "2025-06-04T15:37:04.012635Z",
     "iopub.status.idle": "2025-06-04T15:37:04.021683Z",
     "shell.execute_reply": "2025-06-04T15:37:04.021004Z",
     "shell.execute_reply.started": "2025-06-04T15:37:04.013189Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# cerate test-like train - add rows for all shops&items&periods product. For combinations not in original data fill 0\n",
    "\n",
    "def create_testlike_train(df):\n",
    "    matrix = []\n",
    "    min_date = df['date'].min()\n",
    "    for i in range(df['date_block_num'].min(), df['date_block_num'].max()+1):\n",
    "        shops = df[df['date_block_num'] == i]['shop_id'].unique()\n",
    "        items = df[df['date_block_num'] == i]['item_id'].unique()\n",
    "        month_start = min_date + pd.tseries.offsets.DateOffset(months = i)\n",
    "        matrix.append( np.array( list(product([i],[month_start],shops,items))))\n",
    "    df_new = pd.DataFrame(np.vstack(matrix),columns = ['date_block_num','month_start','shop_id','item_id'])\n",
    "    pivot = pd.pivot_table(df, \n",
    "                            values = ['item_cnt_day','revenue'], \n",
    "                            index = ['date_block_num','shop_id','item_id'], \n",
    "                            aggfunc = 'sum').reset_index()\n",
    "    pivot2 = pd.pivot_table(df[df['item_cnt_day']>0], \n",
    "                            values = ['item_cnt_day'], \n",
    "                            index = ['date_block_num','shop_id','item_id'], \n",
    "                            aggfunc = 'count').reset_index()\n",
    "    pivot2.rename(columns={'item_cnt_day': 'purch_cnt_month'}, inplace=True)\n",
    "    \n",
    "    df_new = df_new.merge(right = pivot, how = 'left', on = ['date_block_num','shop_id','item_id'], sort = False)\n",
    "    df_new = df_new.merge(right = pivot2, how = 'left', on = ['date_block_num','shop_id','item_id'], sort = False)\n",
    "    \n",
    "    df_new.rename(columns={'item_cnt_day': 'item_cnt_month_uncl'}, inplace=True)\n",
    "    df_new['item_cnt_month_uncl'] = df_new['item_cnt_month_uncl'].fillna(0)\n",
    "    df_new['item_cnt_month'] = df_new['item_cnt_month_uncl'].clip(0,20)\n",
    "    df_new['revenue'] = df_new['revenue'].fillna(0)\n",
    "    df_new['purch_cnt_month'] = df_new['purch_cnt_month'].fillna(0)\n",
    "    df_new['ID'] = -1\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:37:04.022768Z",
     "iopub.status.busy": "2025-06-04T15:37:04.022514Z",
     "iopub.status.idle": "2025-06-04T15:37:57.375991Z",
     "shell.execute_reply": "2025-06-04T15:37:57.375379Z",
     "shell.execute_reply.started": "2025-06-04T15:37:04.022749Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.7 s, sys: 1.59 s, total: 14.2 s\n",
      "Wall time: 14.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = create_testlike_train(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:37:57.378345Z",
     "iopub.status.busy": "2025-06-04T15:37:57.378142Z",
     "iopub.status.idle": "2025-06-04T15:37:57.884892Z",
     "shell.execute_reply": "2025-06-04T15:37:57.883994Z",
     "shell.execute_reply.started": "2025-06-04T15:37:57.37833Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test['date_block_num'] = df['date_block_num'].max()+1\n",
    "test['month_start'] = df['month_start'].max() + pd.tseries.offsets.DateOffset(months = 1)\n",
    "test['item_cnt_month'] = 0\n",
    "test['item_cnt_month_uncl'] = 0\n",
    "test['revenue'] = 0\n",
    "test['purch_cnt_month'] = 0\n",
    "\n",
    "#test['sh_it_key'] = test['shop_id'].astype(str) + ['-']*len(test['shop_id']) + test['item_id'].astype(str)\n",
    "#train_key = list(set(sales['shop_id'].astype(str) + ['-']*len(sales['shop_id']) + sales['item_id'].astype(str)))\n",
    "#test['was_in_s_it_sh'] = test['sh_it_key'].apply(lambda x: 1 if x in train_key else 0)\n",
    "#test.drop('sh_it_key', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:37:57.885966Z",
     "iopub.status.busy": "2025-06-04T15:37:57.885709Z",
     "iopub.status.idle": "2025-06-04T15:37:58.997558Z",
     "shell.execute_reply": "2025-06-04T15:37:58.996658Z",
     "shell.execute_reply.started": "2025-06-04T15:37:57.885944Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8812244, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat train and test to a single df\n",
    "df = df[['ID','date_block_num','month_start','shop_id','item_id','item_cnt_month_uncl','item_cnt_month','purch_cnt_month','revenue']]\n",
    "test = test[['ID','date_block_num','month_start','shop_id','item_id','item_cnt_month_uncl','item_cnt_month','purch_cnt_month','revenue']]\n",
    "df = pd.concat([df,test], ignore_index=True, join = 'inner')\n",
    "#del(test)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:37:58.998756Z",
     "iopub.status.busy": "2025-06-04T15:37:58.998478Z",
     "iopub.status.idle": "2025-06-04T15:38:00.188266Z",
     "shell.execute_reply": "2025-06-04T15:38:00.187071Z",
     "shell.execute_reply.started": "2025-06-04T15:37:58.998737Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df['ID'] = df['ID'].astype('int32')\n",
    "df['date_block_num'] = df['date_block_num'].astype('int8')\n",
    "df['shop_id'] = df['shop_id'].astype('int8')\n",
    "df['item_id'] = df['item_id'].astype('int16')\n",
    "df['item_cnt_month'] = df['item_cnt_month'].astype('float32')\n",
    "df['item_cnt_month_uncl'] = df['item_cnt_month_uncl'].astype('float32')\n",
    "df['revenue'] = df['revenue'].astype('float32')\n",
    "df['purch_cnt_month'] = df['purch_cnt_month'].astype('float32')\n",
    "#df['was_in_s_it_sh'] = df['was_in_s_it_sh'].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:38:00.189393Z",
     "iopub.status.busy": "2025-06-04T15:38:00.189132Z",
     "iopub.status.idle": "2025-06-04T15:38:00.956185Z",
     "shell.execute_reply": "2025-06-04T15:38:00.955193Z",
     "shell.execute_reply.started": "2025-06-04T15:38:00.189372Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#add months and days in month features\n",
    "df['month'] = df['month_start'].dt.month.astype('int8')\n",
    "#df['year'] = df['month_start'].dt.year.astype('int16')\n",
    "df.drop(['month_start'], axis = 1, inplace = True)\n",
    "\n",
    "days = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])\n",
    "df['days_in_m'] = (df['month']-1).map(days).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:38:00.957334Z",
     "iopub.status.busy": "2025-06-04T15:38:00.957114Z",
     "iopub.status.idle": "2025-06-04T15:38:00.96296Z",
     "shell.execute_reply": "2025-06-04T15:38:00.962111Z",
     "shell.execute_reply.started": "2025-06-04T15:38:00.957316Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# add city and type features\n",
    "shops['shop_city'] = shops['shop_name'].apply(lambda x: x.split()[0])\n",
    "shops['shop_type'] = shops['shop_name'].apply(lambda x: x.split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:38:00.96433Z",
     "iopub.status.busy": "2025-06-04T15:38:00.963833Z",
     "iopub.status.idle": "2025-06-04T15:38:07.639278Z",
     "shell.execute_reply": "2025-06-04T15:38:07.638522Z",
     "shell.execute_reply.started": "2025-06-04T15:38:00.964313Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# add item categories features\n",
    "item_categories['split'] = item_categories['item_category_name'].str.split('-')\n",
    "item_categories['item_category_type'] = item_categories['split'].map(lambda x: x[0].strip())\n",
    "item_categories['item_category_subtype'] = item_categories['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\n",
    "item_categories.drop('split', axis = 1, inplace = True)\n",
    "\n",
    "df = df.merge(items, \n",
    "              how='left', \n",
    "              on='item_id').merge(item_categories, \n",
    "                                  how ='left', \n",
    "                                  on='item_category_id').merge(shops, how = 'left', on='shop_id')\n",
    "\n",
    "df['item_category_id'] = df['item_category_id'].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:38:07.640237Z",
     "iopub.status.busy": "2025-06-04T15:38:07.640059Z",
     "iopub.status.idle": "2025-06-04T15:38:14.038735Z",
     "shell.execute_reply": "2025-06-04T15:38:14.038007Z",
     "shell.execute_reply.started": "2025-06-04T15:38:07.640224Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# encode categorical features\n",
    "features_to_encode=['shop_city',\n",
    "                    'shop_type',\n",
    "                    'item_category_type',\n",
    "                    'item_category_subtype']\n",
    "def encode_cat_features(df,features_to_encode):\n",
    "    for feat in features_to_encode:\n",
    "        df[feat+'_encoded'] = LabelEncoder().fit_transform( df[feat] )\n",
    "    df.drop(features_to_encode, axis = 1, inplace = True)\n",
    "    return df\n",
    "\n",
    "df = encode_cat_features(df,features_to_encode)\n",
    "\n",
    "df.drop(['item_category_name','shop_name','item_name'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:46:31.957824Z",
     "iopub.status.busy": "2025-06-04T15:46:31.957528Z",
     "iopub.status.idle": "2025-06-04T15:46:31.964361Z",
     "shell.execute_reply": "2025-06-04T15:46:31.963675Z",
     "shell.execute_reply.started": "2025-06-04T15:46:31.957806Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# add mean encoded features\n",
    "def add_mean_encoded_feat(df):\n",
    "    pivot_it = pd.pivot_table(df, values = ['item_cnt_month',], index = ['item_id','date_block_num'], aggfunc = ['sum','count']).reset_index()\n",
    "    pivot_it.columns = ['item_id','date_block_num','item_cnt_month_sum','item_cnt_month_cnt']\n",
    "    pivot_it['lagged_it_mean'] = ((pivot_it.groupby(['item_id'])['item_cnt_month_sum'].cumsum() - pivot_it['item_cnt_month_sum'])/(pivot_it.groupby(['item_id'])['item_cnt_month_cnt'].cumsum() - pivot_it['item_cnt_month_cnt'])).fillna(0)\n",
    "    pivot_it.drop(['item_cnt_month_sum','item_cnt_month_cnt'], axis = 1, inplace = True)\n",
    "    df =  df.merge(right = pivot_it, how = 'left', on = ['item_id','date_block_num'], sort = False)\n",
    "    \n",
    "    pivot_sh_it = pd.pivot_table(df, values = 'item_cnt_month', index = ['shop_id','item_id','date_block_num'], aggfunc = 'sum').reset_index()\n",
    "    pivot_sh_it['lagged_sh_it_mean'] = ((pivot_sh_it.groupby(['shop_id','item_id'])['item_cnt_month'].cumsum() - pivot_sh_it['item_cnt_month'])/(pivot_sh_it.groupby(['shop_id','item_id'])['item_cnt_month'].cumcount())).fillna(0)\n",
    "    pivot_sh_it.drop(['item_cnt_month'], axis = 1, inplace = True)\n",
    "    df =  df.merge(right = pivot_sh_it, how = 'left', on = ['shop_id','item_id','date_block_num'], sort = False)\n",
    "    df['lagged_it_mean'] = df['lagged_it_mean'].astype('float32')\n",
    "    df['lagged_sh_it_mean'] = df['lagged_sh_it_mean'].astype('float32')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:46:31.965231Z",
     "iopub.status.busy": "2025-06-04T15:46:31.965013Z",
     "iopub.status.idle": "2025-06-04T15:46:44.194454Z",
     "shell.execute_reply": "2025-06-04T15:46:44.193566Z",
     "shell.execute_reply.started": "2025-06-04T15:46:31.965217Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.41 s, sys: 1.03 s, total: 6.44 s\n",
      "Wall time: 6.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = add_mean_encoded_feat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:46:44.195942Z",
     "iopub.status.busy": "2025-06-04T15:46:44.195363Z",
     "iopub.status.idle": "2025-06-04T15:46:44.202716Z",
     "shell.execute_reply": "2025-06-04T15:46:44.201877Z",
     "shell.execute_reply.started": "2025-06-04T15:46:44.195916Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#add lag features\n",
    "def add_lag_feat(df, col_to_agg, group_levels, n_lags, aggfunc = 'mean', clip = False):\n",
    "    new_col_title_code = '_'.join([x for x in group_levels if x != 'date_block_num'])\n",
    "    pivot = pd.pivot_table(df, values = col_to_agg, index = group_levels, aggfunc = aggfunc).reset_index()        \n",
    "    pivot.rename(columns = {col_to_agg[0] : col_to_agg[0] + '_' + aggfunc}, inplace = True)\n",
    "    idx_cols = ['date_block_num','shop_id','item_id']\n",
    "    cols = list(set(idx_cols+group_levels))\n",
    "    df_tech = df[cols].copy()\n",
    "    df_tech = df_tech.merge(right = pivot, how = 'left', on = group_levels, sort = False)\n",
    "    list_of_new_col = [] \n",
    "    for lag in n_lags:\n",
    "        df_to_shift = df_tech[idx_cols+[col_to_agg[0] + '_' + aggfunc]].copy()\n",
    "        df_to_shift['date_block_num'] = df_to_shift['date_block_num'] + lag\n",
    "        df_to_shift.rename(columns={col_to_agg[0] + '_' + aggfunc : col_to_agg[0]+'_'+new_col_title_code + '_' + aggfunc+ '_lag_'+str(lag)}, inplace=True)\n",
    "        list_of_new_col.append(col_to_agg[0]+'_'+new_col_title_code + '_' + aggfunc+ '_lag_'+str(lag))\n",
    "        df= df.merge(right = df_to_shift, how = 'left', on = idx_cols, sort = False)\n",
    "    for col in list_of_new_col:\n",
    "        df[col] = df[col].fillna(0).astype('float32')\n",
    "        if clip:\n",
    "            df[col] = df[col].clip(0,20)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:46:44.203879Z",
     "iopub.status.busy": "2025-06-04T15:46:44.20347Z",
     "iopub.status.idle": "2025-06-04T15:47:24.794867Z",
     "shell.execute_reply": "2025-06-04T15:47:24.794073Z",
     "shell.execute_reply.started": "2025-06-04T15:46:44.203853Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df = add_lag_feat(df, \n",
    "#                   col_to_agg = ['item_cnt_month'],\n",
    "#                   group_levels = ['date_block_num','shop_id','item_id'], \n",
    "#                   n_lags = [1,2,3], \n",
    "#                   aggfunc = 'sum')\n",
    "\n",
    "# df = add_lag_feat(df, \n",
    "#                   col_to_agg = ['purch_cnt_month'],\n",
    "#                   group_levels = ['date_block_num','shop_id','item_id'], \n",
    "#                   n_lags = [1,2], \n",
    "#                   aggfunc = 'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:47:24.796256Z",
     "iopub.status.busy": "2025-06-04T15:47:24.795942Z",
     "iopub.status.idle": "2025-06-04T15:47:26.696297Z",
     "shell.execute_reply": "2025-06-04T15:47:26.695689Z",
     "shell.execute_reply.started": "2025-06-04T15:47:24.796233Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# df['it_cnt_sh_it_lag_avg'] = df[['item_cnt_month_shop_id_item_id_sum_lag_1', \n",
    "#                                  'item_cnt_month_shop_id_item_id_sum_lag_2', \n",
    "#                                  'item_cnt_month_shop_id_item_id_sum_lag_3']].mean(skipna=True, axis=1)\n",
    "\n",
    "# df['it_cnt_sh_it_lag_grad'] = df['item_cnt_month_shop_id_item_id_sum_lag_1']/df['item_cnt_month_shop_id_item_id_sum_lag_2']\n",
    "\n",
    "# df['it_cnt_sh_it_lag_avg'] = df['it_cnt_sh_it_lag_avg'].astype('float32')\n",
    "# df['it_cnt_sh_it_lag_grad'] = df['it_cnt_sh_it_lag_grad'].replace([np.inf, -np.inf], np.nan).fillna(0).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:47:26.697322Z",
     "iopub.status.busy": "2025-06-04T15:47:26.697088Z",
     "iopub.status.idle": "2025-06-04T15:48:56.939791Z",
     "shell.execute_reply": "2025-06-04T15:48:56.939088Z",
     "shell.execute_reply.started": "2025-06-04T15:47:26.697303Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df = add_lag_feat(df, \n",
    "#                   col_to_agg = ['item_cnt_month'],\n",
    "#                   group_levels = ['date_block_num'], \n",
    "#                   n_lags = [1])\n",
    "\n",
    "# df = add_lag_feat(df, \n",
    "#                   col_to_agg = ['item_cnt_month'],\n",
    "#                   group_levels = ['date_block_num','item_id'], \n",
    "#                   n_lags = [1,2])\n",
    "                   \n",
    "# df = add_lag_feat(df, \n",
    "#                   col_to_agg = ['item_cnt_month'],\n",
    "#                   group_levels = ['date_block_num','shop_id'], \n",
    "#                   n_lags = [1,2])\n",
    "# # df = add_lag_feat(df, \n",
    "# #                   col_to_agg = ['revenue'],\n",
    "# #                   group_levels = ['date_block_num','shop_id'], \n",
    "# #                   n_lags = [1])\n",
    "# df = add_lag_feat(df, \n",
    "#                   col_to_agg = ['item_cnt_month'],\n",
    "#                   group_levels = ['date_block_num','item_category_id'], \n",
    "#                   n_lags = [1])\n",
    "# df = add_lag_feat(df, \n",
    "#                   col_to_agg = ['item_cnt_month'],\n",
    "#                   group_levels = ['date_block_num','shop_id','item_category_id'], \n",
    "#                   n_lags = [1])\n",
    "# df = add_lag_feat(df, \n",
    "#                   col_to_agg = ['item_cnt_month'],\n",
    "#                   group_levels = ['date_block_num','shop_id','item_category_type_encoded'], \n",
    "#                   n_lags = [1])\n",
    "# df = add_lag_feat(df, \n",
    "#                   col_to_agg = ['item_cnt_month'],\n",
    "#                   group_levels = ['date_block_num','shop_id','item_category_subtype_encoded'], \n",
    "#                   n_lags = [1])\n",
    "# # df = add_lag_feat(df, \n",
    "# #                   col_to_agg = ['item_cnt_month'],\n",
    "# #                   group_levels = ['date_block_num','shop_city_encoded'], \n",
    "# #                   n_lags = [1])\n",
    "# df = add_lag_feat(df, \n",
    "#                   col_to_agg = ['item_cnt_month'],\n",
    "#                   group_levels = ['date_block_num','shop_city_encoded','item_id'], \n",
    "#                   n_lags = [1])\n",
    "# # df = add_lag_feat(df, \n",
    "# #                   col_to_agg = ['item_cnt_month'],\n",
    "# #                   group_levels = ['date_block_num','shop_city_encoded','item_category_id'], \n",
    "# #                   n_lags = [1])\n",
    "# # df = add_lag_feat(df, \n",
    "# #                   col_to_agg = ['item_cnt_month'],\n",
    "# #                   group_levels = ['date_block_num','shop_city_encoded','item_category_type_encoded'], \n",
    "# #                   n_lags = [1])\n",
    "# # df = add_lag_feat(df, \n",
    "# #                   col_to_agg = ['item_cnt_month'],\n",
    "# #                   group_levels = ['date_block_num','shop_city_encoded','item_category_subtype_encoded'], \n",
    "# #                   n_lags = [1])\n",
    "# # df = add_lag_feat(df, \n",
    "# #                   col_to_agg = ['item_cnt_month'],\n",
    "# #                   group_levels = ['date_block_num','shop_type_encoded'], \n",
    "# #                   n_lags = [1])\n",
    "# df = add_lag_feat(df, \n",
    "#                   col_to_agg = ['item_cnt_month'],\n",
    "#                   group_levels = ['date_block_num','shop_type_encoded','item_id'], \n",
    "#                   n_lags = [1])\n",
    "# # df = add_lag_feat(df, \n",
    "# #                   col_to_agg = ['item_cnt_month'],\n",
    "# #                   group_levels = ['date_block_num','shop_type_encoded','item_category_subtype_encoded'], \n",
    "# #                   n_lags = [1])\n",
    "# df = add_lag_feat(df, \n",
    "#                   col_to_agg = ['item_cnt_month'],\n",
    "#                   group_levels = ['date_block_num','item_category_type_encoded'], \n",
    "#                   n_lags = [1])\n",
    "# df = add_lag_feat(df, \n",
    "#                   col_to_agg = ['item_cnt_month'],\n",
    "#                   group_levels = ['date_block_num','item_category_subtype_encoded'], \n",
    "#                   n_lags = [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:49:08.578336Z",
     "iopub.status.busy": "2025-06-04T15:49:08.578131Z",
     "iopub.status.idle": "2025-06-04T15:49:08.582851Z",
     "shell.execute_reply": "2025-06-04T15:49:08.582086Z",
     "shell.execute_reply.started": "2025-06-04T15:49:08.578321Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "columns_to_exclude = ['ID',\n",
    "                      'item_cnt_month',\n",
    "                      'item_cnt_month_uncl',\n",
    "                      'revenue',\n",
    "                      'purch_cnt_month',\n",
    "                      #'months_since_sh_it_first_s',\n",
    "                      #'months_since_it_first_s',\n",
    "                      #'months_since_sh_first_s', \n",
    "                      #'avg_price_global', \n",
    "#                      'avg_price_mnth_lag1', \n",
    "#                      'avg_price_mnth_lag2',\n",
    "#                      'avg_price_mnth_sh_lag1', \n",
    "#                      'avg_price_mnth_sh_lag2'\n",
    "#                      'avg_price_mnth_to_gl', \n",
    "#                      'avg_price_mnth_sh_to_gl', \n",
    "#                      'months_from_sh_it_last_s',\n",
    "#                      'months_from_it_last_s',\n",
    "                      'lagged_sh_it_mean',\n",
    "                      'lagged_it_mean',\n",
    "#                      'it_had_sales_before'\n",
    "#                      'sh_it_had_sales_before'\n",
    "                     ]\n",
    "cat_features = ['month',\n",
    "#                'year',\n",
    "                'shop_id',\n",
    "                'shop_city_encoded',\n",
    "                'shop_type_encoded',\n",
    "                'item_category_id',\n",
    "                'item_category_type_encoded',\n",
    "                'item_category_subtype_encoded',\n",
    "                'days_in_m'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'date_block_num', 'shop_id', 'item_id', 'item_cnt_month_uncl',\n",
       "       'item_cnt_month', 'purch_cnt_month', 'revenue', 'month', 'days_in_m',\n",
       "       'item_category_id', 'shop_city_encoded', 'shop_type_encoded',\n",
       "       'item_category_type_encoded', 'item_category_subtype_encoded',\n",
       "       'lagged_it_mean', 'lagged_sh_it_mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date_block_num', 'shop_id', 'item_id', 'month', 'days_in_m',\n",
      "       'item_category_id', 'shop_city_encoded', 'shop_type_encoded',\n",
      "       'item_category_type_encoded', 'item_category_subtype_encoded'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_data.data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T15:49:08.583863Z",
     "iopub.status.busy": "2025-06-04T15:49:08.583627Z",
     "iopub.status.idle": "2025-06-04T15:52:16.069218Z",
     "shell.execute_reply": "2025-06-04T15:52:16.068658Z",
     "shell.execute_reply.started": "2025-06-04T15:49:08.583849Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# modeling\n",
    "params = {'metric': 'rmse',\n",
    "          'objective': 'mse',\n",
    "          'num_leaves': 255,\n",
    "          'learning_rate': 0.005,\n",
    "          'feature_fraction': 0.75,\n",
    "          'bagging_fraction': 0.75,\n",
    "          'bagging_freq': 5,\n",
    "          'force_col_wise' : True,\n",
    "          'random_state': 10}\n",
    "\n",
    "# Prepare training and validation datasets with categorical features\n",
    "train_data = lgb.Dataset(\n",
    "    df[(df['date_block_num'] >= 19) & (df['date_block_num'] < 33)].drop(columns_to_exclude, axis=1),\n",
    "    label=df[(df['date_block_num'] >= 19) & (df['date_block_num'] < 33)]['item_cnt_month'],\n",
    "    categorical_feature=cat_features\n",
    ")\n",
    "\n",
    "valid_data = lgb.Dataset(\n",
    "    df[df['date_block_num'] == 33].drop(columns_to_exclude, axis=1),\n",
    "    label=df[df['date_block_num'] == 33]['item_cnt_month'],\n",
    "    categorical_feature=cat_features,\n",
    "    reference=train_data\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 524\n",
      "[LightGBM] [Info] Number of data points in the train set: 3224048, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.301487\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 1.11226\tvalid_1's rmse: 0.996967\n",
      "[200]\ttraining's rmse: 1.06147\tvalid_1's rmse: 0.961695\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m lgb_model = \u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter_venv/lib/python3.12/site-packages/lightgbm/engine.py:322\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[32m    311\u001b[39m     cb(\n\u001b[32m    312\u001b[39m         callback.CallbackEnv(\n\u001b[32m    313\u001b[39m             model=booster,\n\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m         )\n\u001b[32m    320\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[43mbooster\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] = []\n\u001b[32m    325\u001b[39m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter_venv/lib/python3.12/site-packages/lightgbm/basic.py:4155\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, train_set, fobj)\u001b[39m\n\u001b[32m   4152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__set_objective_to_none:\n\u001b[32m   4153\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[33m\"\u001b[39m\u001b[33mCannot update due to null objective function.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4154\u001b[39m _safe_call(\n\u001b[32m-> \u001b[39m\u001b[32m4155\u001b[39m     \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4156\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4158\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4159\u001b[39m )\n\u001b[32m   4160\u001b[39m \u001b[38;5;28mself\u001b[39m.__is_predicted_cur_iter = [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.__num_dataset)]\n\u001b[32m   4161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished.value == \u001b[32m1\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "lgb_model = lgb.train(\n",
    "    params=params,\n",
    "    train_set=train_data,\n",
    "    num_boost_round=1500,\n",
    "    valid_sets=[train_data, valid_data],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=100), lgb.log_evaluation(100)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 868304,
     "sourceId": 8587,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "jupyter_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
